{
  "snapshot_version": "1.0",
  "generated_at_utc": "2026-02-10T04:29:01.534099+00:00",
  "normalization_rules": {
    "provider_id_normalization": "trim + lowercase",
    "dedupe": "set-union then sorted lexicographically"
  },
  "sources": {
    "models_dev": {
      "source_url": "https://models.dev/api.json",
      "fetched_at_utc": "2026-02-10T04:29:01.534153+00:00",
      "content_sha256": "05c6a0bf724a76231a97ed1c35f5dc6e58b504169399f5eb71b11c914b5948c7",
      "raw_provider_ids": [
        "302ai",
        "abacus",
        "aihubmix",
        "alibaba",
        "alibaba-cn",
        "amazon-bedrock",
        "anthropic",
        "azure",
        "azure-cognitive-services",
        "bailing",
        "baseten",
        "berget",
        "cerebras",
        "chutes",
        "cloudflare-ai-gateway",
        "cloudflare-workers-ai",
        "cohere",
        "cortecs",
        "deepinfra",
        "deepseek",
        "fastrouter",
        "fireworks-ai",
        "firmware",
        "friendli",
        "github-copilot",
        "github-models",
        "gitlab",
        "google",
        "google-vertex",
        "google-vertex-anthropic",
        "groq",
        "helicone",
        "huggingface",
        "iflowcn",
        "inception",
        "inference",
        "io-net",
        "jiekou",
        "kimi-for-coding",
        "llama",
        "lmstudio",
        "lucidquery",
        "minimax",
        "minimax-cn",
        "minimax-cn-coding-plan",
        "minimax-coding-plan",
        "mistral",
        "moark",
        "modelscope",
        "moonshotai",
        "moonshotai-cn",
        "morph",
        "nano-gpt",
        "nebius",
        "nova",
        "novita-ai",
        "nvidia",
        "ollama-cloud",
        "openai",
        "opencode",
        "openrouter",
        "ovhcloud",
        "perplexity",
        "poe",
        "privatemode-ai",
        "requesty",
        "sap-ai-core",
        "scaleway",
        "siliconflow",
        "siliconflow-cn",
        "submodel",
        "synthetic",
        "togetherai",
        "upstage",
        "v0",
        "venice",
        "vercel",
        "vivgrid",
        "vultr",
        "wandb",
        "xai",
        "xiaomi",
        "zai",
        "zai-coding-plan",
        "zenmux",
        "zhipuai",
        "zhipuai-coding-plan"
      ],
      "normalized_provider_ids": [
        "302ai",
        "abacus",
        "aihubmix",
        "alibaba",
        "alibaba-cn",
        "amazon-bedrock",
        "anthropic",
        "azure",
        "azure-cognitive-services",
        "bailing",
        "baseten",
        "berget",
        "cerebras",
        "chutes",
        "cloudflare-ai-gateway",
        "cloudflare-workers-ai",
        "cohere",
        "cortecs",
        "deepinfra",
        "deepseek",
        "fastrouter",
        "fireworks-ai",
        "firmware",
        "friendli",
        "github-copilot",
        "github-models",
        "gitlab",
        "google",
        "google-vertex",
        "google-vertex-anthropic",
        "groq",
        "helicone",
        "huggingface",
        "iflowcn",
        "inception",
        "inference",
        "io-net",
        "jiekou",
        "kimi-for-coding",
        "llama",
        "lmstudio",
        "lucidquery",
        "minimax",
        "minimax-cn",
        "minimax-cn-coding-plan",
        "minimax-coding-plan",
        "mistral",
        "moark",
        "modelscope",
        "moonshotai",
        "moonshotai-cn",
        "morph",
        "nano-gpt",
        "nebius",
        "nova",
        "novita-ai",
        "nvidia",
        "ollama-cloud",
        "openai",
        "opencode",
        "openrouter",
        "ovhcloud",
        "perplexity",
        "poe",
        "privatemode-ai",
        "requesty",
        "sap-ai-core",
        "scaleway",
        "siliconflow",
        "siliconflow-cn",
        "submodel",
        "synthetic",
        "togetherai",
        "upstage",
        "v0",
        "venice",
        "vercel",
        "vivgrid",
        "vultr",
        "wandb",
        "xai",
        "xiaomi",
        "zai",
        "zai-coding-plan",
        "zenmux",
        "zhipuai",
        "zhipuai-coding-plan"
      ],
      "count": 87,
      "extraction_commands": [
        "curl -sSL https://models.dev/api.json > /tmp/models_dev_api.json",
        "sha256sum /tmp/models_dev_api.json",
        "jq -r 'keys[]' /tmp/models_dev_api.json | sort -u"
      ]
    },
    "opencode": {
      "repo": "https://github.com/opencode-ai/opencode",
      "ref": "73ee493265acf15fcd8caab2bc8cd3bd375b63cb",
      "commit_date": "2025-09-17T21:56:54-04:00",
      "source_hashes": {
        "internal/llm/provider/provider.go": "1945a448c8d3ac08f8f96e5c495507ec887a3a451fc8f96889bc3492fa30fd45",
        "internal/llm/models/*.go": "6ce6fb5d77187751b20dca8da2d119370ca8e767d38f3a4dadfba598760766fb",
        "README.md": "719f545372b02ea4aa973c5e97b9d2347655b5ac733cbd505c47fd2fdf2a19b8"
      },
      "raw": {
        "provider_constant_map": [
          {
            "constant": "ProviderAnthropic",
            "provider_id": "anthropic"
          },
          {
            "constant": "ProviderAzure",
            "provider_id": "azure"
          },
          {
            "constant": "ProviderBedrock",
            "provider_id": "bedrock"
          },
          {
            "constant": "ProviderCopilot",
            "provider_id": "copilot"
          },
          {
            "constant": "ProviderGROQ",
            "provider_id": "groq"
          },
          {
            "constant": "ProviderGemini",
            "provider_id": "gemini"
          },
          {
            "constant": "ProviderLocal",
            "provider_id": "local"
          },
          {
            "constant": "ProviderMock",
            "provider_id": "__mock"
          },
          {
            "constant": "ProviderOpenAI",
            "provider_id": "openai"
          },
          {
            "constant": "ProviderOpenRouter",
            "provider_id": "openrouter"
          },
          {
            "constant": "ProviderVertexAI",
            "provider_id": "vertexai"
          },
          {
            "constant": "ProviderXAI",
            "provider_id": "xai"
          }
        ],
        "provider_switch_constants": [
          "ProviderAnthropic",
          "ProviderAzure",
          "ProviderBedrock",
          "ProviderCopilot",
          "ProviderGROQ",
          "ProviderGemini",
          "ProviderLocal",
          "ProviderMock",
          "ProviderOpenAI",
          "ProviderOpenRouter",
          "ProviderVertexAI",
          "ProviderXAI"
        ],
        "runtime_provider_ids": [
          "__mock",
          "anthropic",
          "azure",
          "bedrock",
          "copilot",
          "gemini",
          "groq",
          "local",
          "openai",
          "openrouter",
          "vertexai",
          "xai"
        ],
        "readme_provider_ids": [
          "__mock",
          "anthropic",
          "azure",
          "bedrock",
          "copilot",
          "gemini",
          "groq",
          "local",
          "openai",
          "openrouter",
          "vertexai",
          "xai"
        ],
        "readme_notes": [
          "README includes a providers config snippet and a self-hosted LOCAL_ENDPOINT provider path.",
          "Normalized opencode IDs exclude internal non-production IDs prefixed with __ (e.g. __mock)."
        ]
      },
      "normalized_provider_ids": [
        "anthropic",
        "azure",
        "bedrock",
        "copilot",
        "gemini",
        "groq",
        "local",
        "openai",
        "openrouter",
        "vertexai",
        "xai"
      ],
      "count": 11,
      "extraction_commands": [
        "git clone https://github.com/opencode-ai/opencode && cd opencode && git checkout 73ee493265acf15fcd8caab2bc8cd3bd375b63cb",
        "grep -E 'case models\\.Provider' internal/llm/provider/provider.go",
        "grep -RhoE 'Provider[A-Za-z0-9_]+\\s+ModelProvider\\s*=\\s*\"[^\"]+\"' internal/llm/models",
        "rg -n '\\*\\*Multiple AI Providers\\*\\*|\\\"providers\\\"|LOCAL_ENDPOINT' README.md"
      ]
    },
    "code": {
      "repo": "https://github.com/openai/codex",
      "ref": "168c359b71c758002a8fcbf04a957c8b1c03cc52",
      "commit_date": "2026-02-09T20:03:32-08:00",
      "source_hashes": {
        "codex-rs/core/src/model_provider_info.rs": "93eb6b6e9ce44dd2dca80ee56a8b3033b0da498e15f1e704d4e604206850be96",
        "codex-rs/core/src/config/mod.rs": "0b24849a861a3a9a297af4a8536855a0654dc13d5e1d0c2ab96e164e8b8ae7d2",
        "codex-rs/core/config.schema.json": "3d98ede34fd2cfb4b353bec00d49a3c92ada193f1597a6701742e5d456c1c2e6",
        "docs/config.md": "9251ea6898e3b9051b4b70495d91d6541ac1591e6c43ce3d13bdf6ed94774d75"
      },
      "raw": {
        "built_in_provider_ids": [
          "openai",
          "ollama",
          "lmstudio"
        ],
        "legacy_provider_ids_removed": [
          "ollama-chat"
        ],
        "config_example_custom_provider_ids": [
          "openai-custom"
        ],
        "model_provider_semantics": [
          "`model_provider` selects a key from the `model_providers` map.",
          "Built-ins are loaded via `built_in_model_providers()` and user config can add/override providers in `[model_providers.<id>]`.",
          "Current built-ins in pinned commit are openai + oss providers (ollama, lmstudio)."
        ],
        "schema_descriptions": [
          "The key in the `model_providers` map identifying the [`ModelProviderInfo`] to use.",
          "Provider to use from the model_providers map."
        ]
      },
      "normalized_provider_ids": [
        "lmstudio",
        "ollama",
        "openai"
      ],
      "count": 3,
      "extraction_commands": [
        "git clone https://github.com/openai/codex && cd codex && git checkout 168c359b71c758002a8fcbf04a957c8b1c03cc52",
        "rg -n 'built_in_model_providers|OLLAMA_OSS_PROVIDER_ID|LMSTUDIO_OSS_PROVIDER_ID' codex-rs/core/src/model_provider_info.rs",
        "rg -n 'model_provider|model_providers' codex-rs/core/src/config/mod.rs codex-rs/core/config.schema.json"
      ]
    }
  },
  "combined": {
    "normalized_provider_ids_union": [
      "302ai",
      "abacus",
      "aihubmix",
      "alibaba",
      "alibaba-cn",
      "amazon-bedrock",
      "anthropic",
      "azure",
      "azure-cognitive-services",
      "bailing",
      "baseten",
      "bedrock",
      "berget",
      "cerebras",
      "chutes",
      "cloudflare-ai-gateway",
      "cloudflare-workers-ai",
      "cohere",
      "copilot",
      "cortecs",
      "deepinfra",
      "deepseek",
      "fastrouter",
      "fireworks-ai",
      "firmware",
      "friendli",
      "gemini",
      "github-copilot",
      "github-models",
      "gitlab",
      "google",
      "google-vertex",
      "google-vertex-anthropic",
      "groq",
      "helicone",
      "huggingface",
      "iflowcn",
      "inception",
      "inference",
      "io-net",
      "jiekou",
      "kimi-for-coding",
      "llama",
      "lmstudio",
      "local",
      "lucidquery",
      "minimax",
      "minimax-cn",
      "minimax-cn-coding-plan",
      "minimax-coding-plan",
      "mistral",
      "moark",
      "modelscope",
      "moonshotai",
      "moonshotai-cn",
      "morph",
      "nano-gpt",
      "nebius",
      "nova",
      "novita-ai",
      "nvidia",
      "ollama",
      "ollama-cloud",
      "openai",
      "opencode",
      "openrouter",
      "ovhcloud",
      "perplexity",
      "poe",
      "privatemode-ai",
      "requesty",
      "sap-ai-core",
      "scaleway",
      "siliconflow",
      "siliconflow-cn",
      "submodel",
      "synthetic",
      "togetherai",
      "upstage",
      "v0",
      "venice",
      "vercel",
      "vertexai",
      "vivgrid",
      "vultr",
      "wandb",
      "xai",
      "xiaomi",
      "zai",
      "zai-coding-plan",
      "zenmux",
      "zhipuai",
      "zhipuai-coding-plan"
    ],
    "counts": {
      "models_dev": 87,
      "opencode": 11,
      "code_builtin": 3,
      "union": 93
    }
  }
}
